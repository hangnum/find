# NL-Find Configuration
# This file provides default configuration for the application.
# Environment variables take precedence over these settings.

llm:
  # LLM provider name: openai, deepseek, ollama, etc.
  provider: openai
  # Model name to use
  model: gpt-4o-mini
  # API key (can also be set via LLM_API_KEY or OPENAI_API_KEY env var)
  # api_key: your-api-key-here
  # Custom API endpoint URL (for Ollama, DeepSeek, etc.)
  # base_url: http://localhost:11434/v1
  # Temperature for response generation (0.0 = deterministic)
  temperature: 0.0
  # Maximum tokens in response
  max_tokens: 1024

search:
  # Search backend: auto, fd, find, everything, python
  backend: auto
  # Maximum number of results to return
  max_results: 1000
  # Whether to include hidden files by default
  include_hidden: false
  # Whether to search recursively by default
  recursive: true

ui:
  # UI theme: dark or light
  theme: dark
  # UI language
  language: zh_CN
  # Whether to show file preview panel
  show_preview: true
